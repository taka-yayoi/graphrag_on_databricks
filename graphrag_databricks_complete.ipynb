{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbff399-ceef-4be4-a305-af67f9ee39a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Microsoft GraphRAG on Databricks\n",
    "\n",
    "このノートブックでは、MicrosoftのGraphRAGをDatabricks上で実行する方法を説明します。\n",
    "\n",
    "## GraphRAGとは\n",
    "\n",
    "GraphRAGは、ナレッジグラフを活用したRAG(Retrieval-Augmented Generation)手法です。\n",
    "従来のベクトル検索ベースのRAGと異なり、以下の特徴があります:\n",
    "\n",
    "- **エンティティとリレーションシップの抽出**: テキストから人物、組織、技術などのエンティティと、それらの関係性を抽出\n",
    "- **コミュニティ検出**: 関連するエンティティをクラスタリングし、階層的なコミュニティ構造を構築\n",
    "- **Global Search**: コミュニティレポートを活用し、データセット全体に関する高レベルな質問に回答\n",
    "- **Local Search**: 特定のエンティティに関する詳細な質問に回答\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "- Databricks Runtime 14.0 ML以上\n",
    "- **クラスター**(サーバレスではなく)を使用(LanceDBのファイル操作制約のため)\n",
    "- OpenAI APIキー(Databricks Secretsに格納済み)\n",
    "- Unity Catalogが有効なワークスペース\n",
    "\n",
    "## 参考リンク\n",
    "\n",
    "- [GraphRAG GitHub](https://github.com/microsoft/graphrag)\n",
    "- [GraphRAG Documentation](https://microsoft.github.io/graphrag/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d92049b0-4d58-47bf-be12-75deed440604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. パッケージのインストール\n",
    "\n",
    "GraphRAGと可視化用のパッケージをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "712dc9c8-53dc-4b62-9972-9fd81902df73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.12.1 requires azure-cosmos==4.3.1, but you have azure-cosmos 4.14.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install graphrag pyvis --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9a4327-3af4-4e2f-b109-693230c7e88c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad855b86-2e4e-4cae-b93f-4747b5e0f802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. 作業ディレクトリの設定\n",
    "\n",
    "GraphRAGはLanceDBを使用してベクトルデータを保存しますが、LanceDBの`rename`操作は\n",
    "Unity CatalogボリュームやWorkspaceファイルシステムでサポートされていません。\n",
    "そのため、**ローカルディスク(`/tmp`)** を作業ディレクトリとして使用します。\n",
    "\n",
    "処理完了後、結果はDelta Tableに保存して永続化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5b545db-fe13-4106-a6c4-725b95d793e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作業ディレクトリ: /tmp/graphrag_work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Unity Catalog設定\n",
    "CATALOG = \"takaakiyayoi_catalog\"\n",
    "SCHEMA = \"default\"\n",
    "\n",
    "# 作業ディレクトリ(クラスターのローカルディスク)\n",
    "WORK_DIR = \"/tmp/graphrag_work\"\n",
    "INPUT_DIR = f\"{WORK_DIR}/input\"\n",
    "OUTPUT_DIR = f\"{WORK_DIR}/output\"\n",
    "CACHE_DIR = f\"{WORK_DIR}/cache\"\n",
    "\n",
    "# 既存のディレクトリがあればクリア\n",
    "if os.path.exists(WORK_DIR):\n",
    "    shutil.rmtree(WORK_DIR)\n",
    "\n",
    "# ディレクトリ作成\n",
    "for d in [WORK_DIR, INPUT_DIR, OUTPUT_DIR, CACHE_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"作業ディレクトリ: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1611b02-386f-4dd0-9116-feda98c297d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. サンプルデータの準備\n",
    "\n",
    "GraphRAGのインデックス作成には、テキストデータが必要です。\n",
    "ここではDatabricksエコシステムに関するサンプルテキストを使用します。\n",
    "\n",
    "実際の利用では、このディレクトリに分析したいテキストファイル(.txt)を配置してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4b8ddf3-0e46-4a28-9100-9a8328649ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "サンプルデータを保存しました: /tmp/graphrag_work/input/databricks_overview.txt\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Databricksは、データエンジニアリング、データサイエンス、機械学習のための統合プラットフォームです。\n",
    "Apache Sparkの創設者たちによって設立され、レイクハウスアーキテクチャを提唱しています。\n",
    "\n",
    "Unity Catalogは、Databricksのデータガバナンスソリューションです。\n",
    "データ、MLモデル、AIアセットを一元管理し、きめ細かなアクセス制御を提供します。\n",
    "Unity CatalogはDatabricksワークスペース全体でメタデータを共有できます。\n",
    "\n",
    "MLflowは、機械学習のライフサイクル管理のためのオープンソースプラットフォームです。\n",
    "実験追跡、モデル登録、デプロイメントなどの機能を提供します。\n",
    "MLflow 3では、LoggedModelという新しい概念が導入され、GenAIアプリケーションの管理が強化されました。\n",
    "\n",
    "Delta Lakeは、データレイクに信頼性をもたらすオープンソースのストレージレイヤーです。\n",
    "ACIDトランザクション、スキーマエンフォースメント、タイムトラベルなどの機能を提供します。\n",
    "DatabricksではDelta Lakeがデフォルトのテーブル形式として使用されています。\n",
    "\n",
    "Mosaic AIは、Databricksの生成AIソリューションです。\n",
    "Foundation Modelのファインチューニング、RAGアプリケーション構築、AIエージェント開発をサポートします。\n",
    "Agent Frameworkを使用すると、本番環境向けのAIエージェントを構築できます。\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{INPUT_DIR}/databricks_overview.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(f\"サンプルデータを保存しました: {INPUT_DIR}/databricks_overview.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb77ef6c-7faa-4371-b5fe-437be62c3753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. OpenAI APIキーの取得\n",
    "\n",
    "GraphRAGは現在、**OpenAI API**または**Azure OpenAI**が必要です。\n",
    "\n",
    "**注意**: Databricks Foundation Model API(FMAPI)は、JSON modeの仕様差異により\n",
    "GraphRAGのクエリ機能と互換性がありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ee271f-edc8-4c00-a89b-dd5bed7d89ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI APIキーを取得しました\n"
     ]
    }
   ],
   "source": [
    "# Databricks SecretsからOpenAI APIキーを取得\n",
    "OPENAI_API_KEY = dbutils.secrets.get(scope=\"demo-token-takaaki.yayoi\", key=\"openai_api_key\")\n",
    "print(\"OpenAI APIキーを取得しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36950846-00c0-4b7a-8db2-8af4de3a1ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. 設定ファイルの作成\n",
    "\n",
    "GraphRAGの動作は`settings.yaml`で制御します。\n",
    "主な設定項目:\n",
    "\n",
    "- **models**: 使用するLLMとEmbeddingモデル\n",
    "- **chunks**: テキスト分割の設定\n",
    "- **entity_extraction**: 抽出するエンティティタイプ\n",
    "- **community_reports**: コミュニティレポート生成の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c526f0a-33a7-4c7c-a547-b139e790cf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "設定ファイルを保存しました: /tmp/graphrag_work/settings.yaml\n"
     ]
    }
   ],
   "source": [
    "settings_content = f\"\"\"encoding_model: cl100k_base\n",
    "\n",
    "models:\n",
    "  default_chat_model:\n",
    "    type: openai_chat\n",
    "    api_key: {OPENAI_API_KEY}\n",
    "    model: gpt-4o\n",
    "    encoding_model: cl100k_base\n",
    "    model_supports_json: true\n",
    "    max_retries: 3\n",
    "    request_timeout: 180\n",
    "\n",
    "  default_embedding_model:\n",
    "    type: openai_embedding\n",
    "    api_key: {OPENAI_API_KEY}\n",
    "    model: text-embedding-3-small\n",
    "    encoding_model: cl100k_base\n",
    "\n",
    "chunks:\n",
    "  size: 1200\n",
    "  overlap: 100\n",
    "  group_by_columns:\n",
    "    - id\n",
    "\n",
    "input:\n",
    "  type: file\n",
    "  file_type: text\n",
    "  base_dir: \"{INPUT_DIR}\"\n",
    "  file_encoding: utf-8\n",
    "  file_pattern: \".*\\\\\\\\.txt$$\"\n",
    "\n",
    "cache:\n",
    "  type: file\n",
    "  base_dir: \"{CACHE_DIR}\"\n",
    "\n",
    "storage:\n",
    "  type: file\n",
    "  base_dir: \"{OUTPUT_DIR}\"\n",
    "\n",
    "reporting:\n",
    "  type: file\n",
    "  base_dir: \"{OUTPUT_DIR}\"\n",
    "\n",
    "entity_extraction:\n",
    "  entity_types:\n",
    "    - organization\n",
    "    - person\n",
    "    - technology\n",
    "    - concept\n",
    "  max_gleanings: 1\n",
    "\n",
    "summarize_descriptions:\n",
    "  max_length: 500\n",
    "\n",
    "claim_extraction:\n",
    "  enabled: false\n",
    "\n",
    "community_reports:\n",
    "  max_length: 2000\n",
    "  max_input_length: 8000\n",
    "\n",
    "cluster_graph:\n",
    "  max_cluster_size: 10\n",
    "\n",
    "embed_graph:\n",
    "  enabled: false\n",
    "\n",
    "umap:\n",
    "  enabled: false\n",
    "\n",
    "snapshots:\n",
    "  graphml: true\n",
    "  raw_entities: true\n",
    "  top_level_nodes: true\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{WORK_DIR}/settings.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(settings_content)\n",
    "\n",
    "print(f\"設定ファイルを保存しました: {WORK_DIR}/settings.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f06567-08dd-4474-86b2-c6e9f4b902d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. インデックスの作成\n",
    "\n",
    "GraphRAGのインデックス作成プロセスでは、以下の処理が行われます:\n",
    "\n",
    "1. テキストをチャンクに分割\n",
    "2. LLMでエンティティとリレーションシップを抽出\n",
    "3. ナレッジグラフを構築\n",
    "4. コミュニティ検出(Leidenアルゴリズム)\n",
    "5. 各コミュニティのサマリーレポート生成\n",
    "6. エンティティ説明のEmbedding生成\n",
    "\n",
    "このプロセスにはLLMへの複数回のAPI呼び出しが発生するため、数分かかる場合があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b422a601-9343-405d-a64f-839c02e458ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-11 05:27:17.113502: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\r\n2026-01-11 05:27:17.114301: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\r\n2026-01-11 05:27:17.117436: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\r\n2026-01-11 05:27:17.126619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\nE0000 00:00:1768109237.142158    5685 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\nE0000 00:00:1768109237.146661    5685 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\nW0000 00:00:1768109237.158384    5685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\nW0000 00:00:1768109237.158409    5685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\nW0000 00:00:1768109237.158413    5685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\nW0000 00:00:1768109237.158416    5685 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n2026-01-11 05:27:17.161967: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n/databricks/python/lib/python3.12/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\r\n  \"cipher\": algorithms.TripleDES,\r\n/databricks/python/lib/python3.12/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\r\n  \"class\": algorithms.TripleDES,\r\nModel config based on fnllm is deprecated and will be removed in GraphRAG v3, please use ModelType.Chat or ModelType.Embedding instead to switch to LiteLLM config.\r\nModel config based on fnllm is deprecated and will be removed in GraphRAG v3, please use ModelType.Chat or ModelType.Embedding instead to switch to LiteLLM config.\r\nStarting pipeline with workflows: load_input_documents, create_base_text_units, create_final_documents, extract_graph, finalize_graph, extract_covariates, create_communities, create_final_text_units, create_community_reports, generate_text_embeddings\r\nStarting workflow: load_input_documents\r\n\r\nWorkflow complete: load_input_documents\r\nStarting workflow: create_base_text_units\r\n  1 / 1 ............................................................................................\r\r\nWorkflow complete: create_base_text_units\r\nStarting workflow: create_final_documents\r\n\r\nWorkflow complete: create_final_documents\r\nStarting workflow: extract_graph\r\n  1 / 1 ............................................................................................\r  1 / 1 ............................................................................................\r  1 / 19 \r  2 / 19 ..\r  3 / 19 .......\r  4 / 19 ............\r  5 / 19 .................\r  6 / 19 .......................\r  7 / 19 ............................\r  8 / 19 .................................\r  9 / 19 ......................................\r  10 / 19 ...........................................\r  11 / 19 ................................................\r  12 / 19 .....................................................\r  13 / 19 ..........................................................\r  14 / 19 ................................................................\r  15 / 19 .....................................................................\r  16 / 19 ..........................................................................\r  17 / 19 ...............................................................................\r  18 / 19 .....................................................................................\r  19 / 19 ..........................................................................................\r\r\nWorkflow complete: extract_graph\r\nStarting workflow: finalize_graph\r\n\r\nWorkflow complete: finalize_graph\r\nStarting workflow: extract_covariates\r\n\r\nWorkflow complete: extract_covariates\r\nStarting workflow: create_communities\r\n\r\nWorkflow complete: create_communities\r\nStarting workflow: create_final_text_units\r\n\r\nWorkflow complete: create_final_text_units\r\nStarting workflow: create_community_reports\r\n  1 / 1 ............................................................................................\r  1 / 3 .........................\r  2 / 3 ...........................................................\r  3 / 3 ............................................................................................\r\r\nWorkflow complete: create_community_reports\r\nStarting workflow: generate_text_embeddings\r\n  1 / 1 ............................................................................................\r\u001B[90m[\u001B[0m2026-01-11T05:27:51Z \u001B[33mWARN \u001B[0m lance::dataset::write::insert\u001B[90m]\u001B[0m No existing dataset at /tmp/graphrag_work/output/lancedb/default-entity-description.lance, it will be created\r\n  1 / 1 ............................................................................................\r\u001B[90m[\u001B[0m2026-01-11T05:27:52Z \u001B[33mWARN \u001B[0m lance::dataset::write::insert\u001B[90m]\u001B[0m No existing dataset at /tmp/graphrag_work/output/lancedb/default-community-full_content.lance, it will be created\r\n  1 / 1 ............................................................................................\r\u001B[90m[\u001B[0m2026-01-11T05:27:53Z \u001B[33mWARN \u001B[0m lance::dataset::write::insert\u001B[90m]\u001B[0m No existing dataset at /tmp/graphrag_work/output/lancedb/default-text_unit-text.lance, it will be created\r\n\r\nWorkflow complete: generate_text_embeddings\r\nPipeline complete\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(WORK_DIR)\n",
    "!graphrag index --root ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fe427b6-fce4-4969-94b0-bde70320a793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. 作成されたデータの確認\n",
    "\n",
    "インデックス作成により、以下のParquetファイルが生成されます:\n",
    "\n",
    "- `entities.parquet`: 抽出されたエンティティ\n",
    "- `relationships.parquet`: エンティティ間の関係性\n",
    "- `communities.parquet`: コミュニティ構造\n",
    "- `community_reports.parquet`: 各コミュニティのサマリー\n",
    "- `text_units.parquet`: 分割されたテキストチャンク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4c98f3-b6ae-4c7c-8eec-c92384c80ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 出力ファイル ===\n  communities.parquet: 9.5 KB\n  community_reports.parquet: 55.9 KB\n  context.json: 0.0 KB\n  documents.parquet: 13.2 KB\n  entities.parquet: 9.0 KB\n  graph.graphml: 1.5 KB\n  indexing-engine.log: 28.8 KB\n  relationships.parquet: 7.4 KB\n  stats.json: 1.0 KB\n  text_units.parquet: 15.0 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=== 出力ファイル ===\")\n",
    "for f in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    file_path = f\"{OUTPUT_DIR}/{f}\"\n",
    "    if os.path.isfile(file_path):\n",
    "        size = os.path.getsize(file_path) / 1024\n",
    "        print(f\"  {f}: {size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72ccfa8-068d-4c37-bcda-62a299e4d819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### エンティティの確認\n",
    "\n",
    "抽出されたエンティティ(人物、組織、技術、概念など)を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "663844be-2179-4b2b-a554-16a361a5be69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エンティティ数: 10 件\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>type</th><th>description</th></tr></thead><tbody><tr><td>DATABRICKS</td><td>ORGANIZATION</td><td>Databricks is an integrated platform for data engineering, data science, and machine learning, founded by the creators of Apache Spark and advocates of the Lakehouse architecture</td></tr><tr><td>APACHE SPARK</td><td>ORGANIZATION</td><td>Apache Spark is a unified analytics engine for large-scale data processing, and its creators founded Databricks</td></tr><tr><td>UNITY CATALOG</td><td>ORGANIZATION</td><td>Unity Catalog is Databricks' data governance solution that centralizes management of data, ML models, and AI assets, providing fine-grained access control and metadata sharing across Databricks workspaces</td></tr><tr><td>MLFLOW</td><td>ORGANIZATION</td><td>MLflow is an open-source platform for managing the machine learning lifecycle, offering features like experiment tracking, model registration, and deployment, with MLflow 3 introducing the concept of LoggedModel for enhanced GenAI application management</td></tr><tr><td>DELTA LAKE</td><td>ORGANIZATION</td><td>Delta Lake is an open-source storage layer that brings reliability to data lakes, providing features like ACID transactions, schema enforcement, and time travel, and is used as the default table format in Databricks</td></tr><tr><td>MOSAIC AI</td><td>ORGANIZATION</td><td>Mosaic AI is Databricks' generative AI solution, supporting fine-tuning of Foundation Models, RAG application building, and AI agent development, with the Agent Framework enabling the construction of production-ready AI agents</td></tr><tr><td>FOUNDATION MODEL</td><td>EVENT</td><td>Foundation Model refers to a large AI model that can be fine-tuned for specific tasks, supported by Mosaic AI in Databricks</td></tr><tr><td>RAG APPLICATION</td><td>EVENT</td><td>RAG Application refers to Retrieval-Augmented Generation applications, which are supported by Mosaic AI in Databricks</td></tr><tr><td>AGENT FRAMEWORK</td><td>EVENT</td><td>Agent Framework is a tool within Mosaic AI that enables the construction of production-ready AI agents</td></tr><tr><td>GENAI</td><td></td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "DATABRICKS",
         "ORGANIZATION",
         "Databricks is an integrated platform for data engineering, data science, and machine learning, founded by the creators of Apache Spark and advocates of the Lakehouse architecture"
        ],
        [
         "APACHE SPARK",
         "ORGANIZATION",
         "Apache Spark is a unified analytics engine for large-scale data processing, and its creators founded Databricks"
        ],
        [
         "UNITY CATALOG",
         "ORGANIZATION",
         "Unity Catalog is Databricks' data governance solution that centralizes management of data, ML models, and AI assets, providing fine-grained access control and metadata sharing across Databricks workspaces"
        ],
        [
         "MLFLOW",
         "ORGANIZATION",
         "MLflow is an open-source platform for managing the machine learning lifecycle, offering features like experiment tracking, model registration, and deployment, with MLflow 3 introducing the concept of LoggedModel for enhanced GenAI application management"
        ],
        [
         "DELTA LAKE",
         "ORGANIZATION",
         "Delta Lake is an open-source storage layer that brings reliability to data lakes, providing features like ACID transactions, schema enforcement, and time travel, and is used as the default table format in Databricks"
        ],
        [
         "MOSAIC AI",
         "ORGANIZATION",
         "Mosaic AI is Databricks' generative AI solution, supporting fine-tuning of Foundation Models, RAG application building, and AI agent development, with the Agent Framework enabling the construction of production-ready AI agents"
        ],
        [
         "FOUNDATION MODEL",
         "EVENT",
         "Foundation Model refers to a large AI model that can be fine-tuned for specific tasks, supported by Mosaic AI in Databricks"
        ],
        [
         "RAG APPLICATION",
         "EVENT",
         "RAG Application refers to Retrieval-Augmented Generation applications, which are supported by Mosaic AI in Databricks"
        ],
        [
         "AGENT FRAMEWORK",
         "EVENT",
         "Agent Framework is a tool within Mosaic AI that enables the construction of production-ready AI agents"
        ],
        [
         "GENAI",
         "",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entities_df = pd.read_parquet(f\"{OUTPUT_DIR}/entities.parquet\")\n",
    "print(f\"エンティティ数: {len(entities_df)} 件\")\n",
    "display(entities_df[[\"title\", \"type\", \"description\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58130a3a-d511-476c-859b-2913d4c39120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### リレーションシップの確認\n",
    "\n",
    "エンティティ間の関係性を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f080a199-9b7e-4cde-bc76-2090f9529f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "リレーションシップ数: 9 件\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>source</th><th>target</th><th>description</th></tr></thead><tbody><tr><td>DATABRICKS</td><td>APACHE SPARK</td><td>Databricks was founded by the creators of Apache Spark</td></tr><tr><td>DATABRICKS</td><td>UNITY CATALOG</td><td>Unity Catalog is a data governance solution provided by Databricks</td></tr><tr><td>DATABRICKS</td><td>MLFLOW</td><td>MLflow is used within Databricks for managing the machine learning lifecycle</td></tr><tr><td>DATABRICKS</td><td>DELTA LAKE</td><td>Delta Lake is used as the default table format in Databricks</td></tr><tr><td>DATABRICKS</td><td>MOSAIC AI</td><td>Mosaic AI is a generative AI solution offered by Databricks</td></tr><tr><td>MLFLOW</td><td>GENAI</td><td>MLflow 3 introduces the concept of LoggedModel to enhance the management of GenAI applications</td></tr><tr><td>MOSAIC AI</td><td>FOUNDATION MODEL</td><td>Mosaic AI supports the fine-tuning of Foundation Models</td></tr><tr><td>MOSAIC AI</td><td>RAG APPLICATION</td><td>Mosaic AI supports the building of RAG applications</td></tr><tr><td>MOSAIC AI</td><td>AGENT FRAMEWORK</td><td>Mosaic AI includes the Agent Framework for building production-ready AI agents</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "DATABRICKS",
         "APACHE SPARK",
         "Databricks was founded by the creators of Apache Spark"
        ],
        [
         "DATABRICKS",
         "UNITY CATALOG",
         "Unity Catalog is a data governance solution provided by Databricks"
        ],
        [
         "DATABRICKS",
         "MLFLOW",
         "MLflow is used within Databricks for managing the machine learning lifecycle"
        ],
        [
         "DATABRICKS",
         "DELTA LAKE",
         "Delta Lake is used as the default table format in Databricks"
        ],
        [
         "DATABRICKS",
         "MOSAIC AI",
         "Mosaic AI is a generative AI solution offered by Databricks"
        ],
        [
         "MLFLOW",
         "GENAI",
         "MLflow 3 introduces the concept of LoggedModel to enhance the management of GenAI applications"
        ],
        [
         "MOSAIC AI",
         "FOUNDATION MODEL",
         "Mosaic AI supports the fine-tuning of Foundation Models"
        ],
        [
         "MOSAIC AI",
         "RAG APPLICATION",
         "Mosaic AI supports the building of RAG applications"
        ],
        [
         "MOSAIC AI",
         "AGENT FRAMEWORK",
         "Mosaic AI includes the Agent Framework for building production-ready AI agents"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "target",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relationships_df = pd.read_parquet(f\"{OUTPUT_DIR}/relationships.parquet\")\n",
    "print(f\"リレーションシップ数: {len(relationships_df)} 件\")\n",
    "display(relationships_df[[\"source\", \"target\", \"description\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7feb97ff-b5e4-4507-9170-9c9f91f63f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### コミュニティレポートの確認\n",
    "\n",
    "関連するエンティティのクラスタ(コミュニティ)と、そのサマリーを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edadb036-ef61-4b50-8d29-f23d86d9fac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コミュニティレポート数: 3 件\n\n=== Databricks and Its Ecosystem ===\nThe community is centered around Databricks, a platform for data engineering, data science, and machine learning, founded by the creators of Apache Spark. Key components of this ecosystem include Apache Spark, Unity Catalog, and Delta Lake, each playing a significant role in enhancing Databricks' capabilities. The relationships between these entities highlight Databricks' focus on data governance, reliability, and large-scale data processing.\n\n=== MLflow and GenAI Integration ===\nThe community is centered around the integration of MLflow, an open-source platform for managing the machine learning lifecycle, with GenAI applications. MLflow 3 introduces the concept of LoggedModel, which enhances the management of GenAI applications, indicating a significant development in the field of machine learning and artificial intelligence.\n\n=== Mosaic AI and Its Ecosystem ===\nThe community is centered around Mosaic AI, a generative AI solution by Databricks, which supports the fine-tuning of Foundation Models, the development of Retrieval-Augmented Generation (RAG) applications, and the construction of production-ready AI agents through its Agent Framework. Mosaic AI acts as the core entity, linking various advanced AI technologies and tools, thereby enhancing the capabilities of AI development and deployment.\n\n"
     ]
    }
   ],
   "source": [
    "reports_df = pd.read_parquet(f\"{OUTPUT_DIR}/community_reports.parquet\")\n",
    "print(f\"コミュニティレポート数: {len(reports_df)} 件\\n\")\n",
    "\n",
    "for _, row in reports_df.iterrows():\n",
    "    print(f\"=== {row['title']} ===\")\n",
    "    print(f\"{row['summary']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e696e00-0f3c-4165-a871-8afe4cc5cfef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. ナレッジグラフの可視化\n",
    "\n",
    "抽出されたエンティティとリレーションシップをグラフとして可視化します。\n",
    "PyVisを使用してインタラクティブなネットワーク図を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94cfde6f-92eb-4c1d-9a84-0255fa701442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "グラフ統計: 10 ノード, 9 エッジ\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# NetworkXグラフを作成\n",
    "G = nx.Graph()\n",
    "\n",
    "# エンティティをノードとして追加\n",
    "for _, row in entities_df.iterrows():\n",
    "    G.add_node(\n",
    "        row[\"title\"],\n",
    "        title=row[\"description\"][:200] if pd.notna(row[\"description\"]) else \"\",\n",
    "        group=row[\"type\"] if pd.notna(row.get(\"type\")) else \"unknown\"\n",
    "    )\n",
    "\n",
    "# リレーションシップをエッジとして追加\n",
    "for _, row in relationships_df.iterrows():\n",
    "    if row[\"source\"] in G.nodes and row[\"target\"] in G.nodes:\n",
    "        G.add_edge(\n",
    "            row[\"source\"],\n",
    "            row[\"target\"],\n",
    "            title=row[\"description\"] if pd.notna(row[\"description\"]) else \"\"\n",
    "        )\n",
    "\n",
    "print(f\"グラフ統計: {G.number_of_nodes()} ノード, {G.number_of_edges()} エッジ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6a3ca14-573b-4ef2-a2c4-607d35a58620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\nグラフを保存しました: /tmp/graphrag_work/output/knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "# PyVisでインタラクティブな可視化\n",
    "net = Network(height=\"600px\", width=\"100%\", bgcolor=\"#ffffff\", font_color=\"black\", notebook=True)\n",
    "\n",
    "# NetworkXグラフをPyVisに変換\n",
    "net.from_nx(G)\n",
    "\n",
    "# 物理演算の設定\n",
    "net.toggle_physics(True)\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"nodes\": {\n",
    "    \"font\": {\"size\": 14},\n",
    "    \"scaling\": {\"min\": 10, \"max\": 30}\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\"inherit\": true},\n",
    "    \"smooth\": {\"type\": \"continuous\"}\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"forceAtlas2Based\": {\n",
    "      \"gravitationalConstant\": -50,\n",
    "      \"centralGravity\": 0.01,\n",
    "      \"springLength\": 100\n",
    "    },\n",
    "    \"solver\": \"forceAtlas2Based\"\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# HTMLファイルとして保存\n",
    "graph_html_path = f\"{OUTPUT_DIR}/knowledge_graph.html\"\n",
    "net.save_graph(graph_html_path)\n",
    "print(f\"グラフを保存しました: {graph_html_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "672abfab-3030-4a9e-94d9-5a4c07e51086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### グラフの表示\n",
    "\n",
    "以下のセルでインタラクティブなナレッジグラフを表示します。\n",
    "ノードをドラッグして移動したり、ホバーして詳細を確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad06e70-1e06-4f92-8981-ad32b1070aea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 600px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"DATABRICKS\", \"label\": \"DATABRICKS\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Databricks is an integrated platform for data engineering, data science, and machine learning, founded by the creators of Apache Spark and advocates of the Lakehouse architecture\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"APACHE SPARK\", \"label\": \"APACHE SPARK\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Apache Spark is a unified analytics engine for large-scale data processing, and its creators founded Databricks\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"UNITY CATALOG\", \"label\": \"UNITY CATALOG\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Unity Catalog is Databricks\\u0027 data governance solution that centralizes management of data, ML models, and AI assets, providing fine-grained access control and metadata sharing across Databricks worksp\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"MLFLOW\", \"label\": \"MLFLOW\", \"shape\": \"dot\", \"size\": 10, \"title\": \"MLflow is an open-source platform for managing the machine learning lifecycle, offering features like experiment tracking, model registration, and deployment, with MLflow 3 introducing the concept of \"}, {\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"DELTA LAKE\", \"label\": \"DELTA LAKE\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Delta Lake is an open-source storage layer that brings reliability to data lakes, providing features like ACID transactions, schema enforcement, and time travel, and is used as the default table forma\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"ORGANIZATION\", \"id\": \"MOSAIC AI\", \"label\": \"MOSAIC AI\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Mosaic AI is Databricks\\u0027 generative AI solution, supporting fine-tuning of Foundation Models, RAG application building, and AI agent development, with the Agent Framework enabling the construction of \"}, {\"font\": {\"color\": \"black\"}, \"group\": \"\", \"id\": \"GENAI\", \"label\": \"GENAI\", \"shape\": \"dot\", \"size\": 10, \"title\": \"\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"EVENT\", \"id\": \"FOUNDATION MODEL\", \"label\": \"FOUNDATION MODEL\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Foundation Model refers to a large AI model that can be fine-tuned for specific tasks, supported by Mosaic AI in Databricks\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"EVENT\", \"id\": \"RAG APPLICATION\", \"label\": \"RAG APPLICATION\", \"shape\": \"dot\", \"size\": 10, \"title\": \"RAG Application refers to Retrieval-Augmented Generation applications, which are supported by Mosaic AI in Databricks\"}, {\"font\": {\"color\": \"black\"}, \"group\": \"EVENT\", \"id\": \"AGENT FRAMEWORK\", \"label\": \"AGENT FRAMEWORK\", \"shape\": \"dot\", \"size\": 10, \"title\": \"Agent Framework is a tool within Mosaic AI that enables the construction of production-ready AI agents\"}]);\n",
       "                  edges = new vis.DataSet([{\"from\": \"DATABRICKS\", \"title\": \"Databricks was founded by the creators of Apache Spark\", \"to\": \"APACHE SPARK\", \"width\": 1}, {\"from\": \"DATABRICKS\", \"title\": \"Unity Catalog is a data governance solution provided by Databricks\", \"to\": \"UNITY CATALOG\", \"width\": 1}, {\"from\": \"DATABRICKS\", \"title\": \"MLflow is used within Databricks for managing the machine learning lifecycle\", \"to\": \"MLFLOW\", \"width\": 1}, {\"from\": \"DATABRICKS\", \"title\": \"Delta Lake is used as the default table format in Databricks\", \"to\": \"DELTA LAKE\", \"width\": 1}, {\"from\": \"DATABRICKS\", \"title\": \"Mosaic AI is a generative AI solution offered by Databricks\", \"to\": \"MOSAIC AI\", \"width\": 1}, {\"from\": \"MLFLOW\", \"title\": \"MLflow 3 introduces the concept of LoggedModel to enhance the management of GenAI applications\", \"to\": \"GENAI\", \"width\": 1}, {\"from\": \"MOSAIC AI\", \"title\": \"Mosaic AI supports the fine-tuning of Foundation Models\", \"to\": \"FOUNDATION MODEL\", \"width\": 1}, {\"from\": \"MOSAIC AI\", \"title\": \"Mosaic AI supports the building of RAG applications\", \"to\": \"RAG APPLICATION\", \"width\": 1}, {\"from\": \"MOSAIC AI\", \"title\": \"Mosaic AI includes the Agent Framework for building production-ready AI agents\", \"to\": \"AGENT FRAMEWORK\", \"width\": 1}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\"nodes\": {\"font\": {\"size\": 14}, \"scaling\": {\"min\": 10, \"max\": 30}}, \"edges\": {\"color\": {\"inherit\": true}, \"smooth\": {\"type\": \"continuous\"}}, \"physics\": {\"forceAtlas2Based\": {\"gravitationalConstant\": -50, \"centralGravity\": 0.01, \"springLength\": 100}, \"solver\": \"forceAtlas2Based\"}};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HTMLファイルを読み込んで表示\n",
    "with open(graph_html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "displayHTML(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f276137c-8e16-43fc-b801-5628ea2e785a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. Global Search\n",
    "\n",
    "Global Searchは、コミュニティレポートを活用して、データセット全体に関する高レベルな質問に回答します。\n",
    "「このデータセットの主要なテーマは何か?」といった要約的な質問に適しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15fc5989-1fd1-4347-9931-1d29424334a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-11 05:28:06.880956: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2026-01-11 05:28:06.881795: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2026-01-11 05:28:06.885131: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2026-01-11 05:28:06.894348: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768109286.910245    5636 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768109286.914896    5636 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768109286.926651    5636 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768109286.926667    5636 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768109286.926669    5636 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768109286.926670    5636 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2026-01-11 05:28:06.930812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/databricks/python/lib/python3.12/site-packages/paramiko/pkey.py:77: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n  class PKey:\n/databricks/python/lib/python3.12/site-packages/paramiko/transport.py:138: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n  class Transport(threading.Thread, ClosingContextManager):\nWARNING:graphrag.config.models.language_model_config:Model config based on fnllm is deprecated and will be removed in GraphRAG v3, please use ModelType.Chat or ModelType.Embedding instead to switch to LiteLLM config.\nWARNING:graphrag.config.models.language_model_config:Model config based on fnllm is deprecated and will be removed in GraphRAG v3, please use ModelType.Chat or ModelType.Embedding instead to switch to LiteLLM config.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import graphrag.api as api\n",
    "from graphrag.config.load_config import load_config\n",
    "\n",
    "# 設定を読み込み\n",
    "graphrag_config = load_config(Path(WORK_DIR))\n",
    "\n",
    "# 必要なデータを読み込み\n",
    "entities = pd.read_parquet(f\"{OUTPUT_DIR}/entities.parquet\")\n",
    "communities = pd.read_parquet(f\"{OUTPUT_DIR}/communities.parquet\")\n",
    "community_reports = pd.read_parquet(f\"{OUTPUT_DIR}/community_reports.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff65c43-f583-4e8b-a07c-29092219ae35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 質問 ===\nこのデータセットで説明されている主要な技術とその関係性を要約してください\n\n=== 回答 ===\n### Databricksの統合プラットフォーム\n\nDatabricksは、データエンジニアリング、データサイエンス、機械学習のための統合プラットフォームとして機能しています。このプラットフォームは、Apache Spark、Unity Catalog、Delta Lakeなどのツールを統合することで、データ処理能力を向上させています [Data: Reports (0)]。これにより、ユーザーは大規模なデータセットを効率的に処理し、分析することが可能になります。\n\n### Apache Sparkの役割\n\nApache Sparkは、Databricksの基盤となるコンポーネントであり、大規模データ処理のための統一分析エンジンを提供します。Databricksの創設者がSparkを開発したことから、DatabricksはSparkの能力に深く依存しています [Data: Reports (0)]。Sparkの強力なデータ処理能力は、Databricksのプラットフォーム全体のパフォーマンスを支えています。\n\n### Unity Catalogによるデータガバナンス\n\nUnity Catalogは、Databricksのデータガバナンスソリューションであり、データ、機械学習モデル、AI資産の管理を中央集権化します。これにより、データ操作のコンプライアンスとデータ整合性が確保されます [Data: Reports (0)]。データガバナンスの強化は、企業がデータを安全かつ効率的に管理するために不可欠です。\n\n### Mosaic AIの役割\n\nMosaic AIは、Databricksの生成AIソリューションとして、Foundation Modelsの微調整、RAGアプリケーションの開発、AIエージェントの構築をサポートする中心的な存在です。これにより、AI開発と展開の能力が強化されます [Data: Reports (2)]。Mosaic AIの導入により、企業はより高度なAIソリューションを迅速に開発することが可能になります。\n\n### MLflowによる機械学習ライフサイクル管理\n\nMLflowは、機械学習ライフサイクル管理のためのオープンソースプラットフォームであり、特にGenAIアプリケーションの管理を強化するLoggedModelの導入により、AI技術の進展に寄与しています [Data: Reports (1)]。MLflowは、モデルのトラッキング、共有、再現性を向上させ、AIプロジェクトの効率を高めます。\n\nこれらの技術は、Databricksのプラットフォームを通じて相互に連携し、データ処理からAI開発までの一連のプロセスを支えています。それぞれの技術が持つ特性と機能が、全体としてのパフォーマンスと効率性を高める要因となっています。\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-a1affcdfbd8c88f780925cb7b52c46b1\", \"tr-1a45679e60e0025dd12d9b1fb8b69d36\"]",
      "text/plain": [
       "[Trace(trace_id=tr-a1affcdfbd8c88f780925cb7b52c46b1), Trace(trace_id=tr-1a45679e60e0025dd12d9b1fb8b69d36)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"このデータセットで説明されている主要な技術とその関係性を要約してください\"\n",
    "\n",
    "response, context = await api.global_search(\n",
    "    config=graphrag_config,\n",
    "    entities=entities,\n",
    "    communities=communities,\n",
    "    community_reports=community_reports,\n",
    "    community_level=2,\n",
    "    dynamic_community_selection=False,\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=query,\n",
    ")\n",
    "\n",
    "print(\"=== 質問 ===\")\n",
    "print(query)\n",
    "print(\"\\n=== 回答 ===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54c063d-0e54-4190-aa4c-f827589ca090",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. Local Search\n",
    "\n",
    "Local Searchは、特定のエンティティに関する詳細な質問に回答します。\n",
    "ベクトル検索でエンティティを特定し、関連するコンテキストを組み合わせて回答を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1619a9ef-f9a9-4a5a-b548-d459943f8500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 質問 ===\nMLflowとは何ですか?どのような機能がありますか?\n\n=== 回答 ===\n## MLflowとは\n\nMLflowは、機械学習のライフサイクル管理を目的としたオープンソースプラットフォームです。Databricks内で使用されており、機械学習プロジェクトの管理を効率化するためのさまざまな機能を提供しています [Data: Entities (3); Relationships (2)]。\n\n## 主な機能\n\n### 実験追跡\n\nMLflowは、実験の追跡機能を提供します。これにより、異なるモデルのパラメータ、メトリクス、アーティファクトを記録し、比較することが可能です。これにより、データサイエンティストは実験の結果を容易に管理し、最適なモデルを選択するための情報を得ることができます。\n\n### モデル登録\n\nMLflowは、モデルの登録機能も備えています。これにより、モデルのバージョン管理が可能となり、異なるバージョンのモデルを簡単に管理し、必要に応じて特定のバージョンをデプロイすることができます。\n\n### デプロイメント\n\nMLflowは、モデルのデプロイメントをサポートしており、開発環境から本番環境へのスムーズな移行を可能にします。これにより、モデルの実装が迅速かつ効率的に行われ、ビジネスニーズに応じた迅速な対応が可能となります。\n\n### GenAIアプリケーション管理\n\nMLflow 3では、LoggedModelという新しい概念が導入され、GenAIアプリケーションの管理が強化されています。これにより、生成AIアプリケーションの管理がより効率的になり、AIソリューションの開発と展開が容易になります [Data: Entities (3, 9); Relationships (5)]。\n\nMLflowは、これらの機能を通じて、機械学習プロジェクトの全体的な管理をサポートし、データサイエンティストやエンジニアがより効率的に作業できる環境を提供しています。\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-94b4a463001486fc75df291e68b6045a\", \"tr-0fecb7cc5dc33d19355d2e8e366a06d1\"]",
      "text/plain": [
       "[Trace(trace_id=tr-94b4a463001486fc75df291e68b6045a), Trace(trace_id=tr-0fecb7cc5dc33d19355d2e8e366a06d1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_units = pd.read_parquet(f\"{OUTPUT_DIR}/text_units.parquet\")\n",
    "relationships = pd.read_parquet(f\"{OUTPUT_DIR}/relationships.parquet\")\n",
    "\n",
    "query_local = \"MLflowとは何ですか?どのような機能がありますか?\"\n",
    "\n",
    "response_local, context_local = await api.local_search(\n",
    "    config=graphrag_config,\n",
    "    entities=entities,\n",
    "    communities=communities,\n",
    "    community_reports=community_reports,\n",
    "    text_units=text_units,\n",
    "    relationships=relationships,\n",
    "    covariates=None,\n",
    "    community_level=2,\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=query_local,\n",
    ")\n",
    "\n",
    "print(\"=== 質問 ===\")\n",
    "print(query_local)\n",
    "print(\"\\n=== 回答 ===\")\n",
    "print(response_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fa6683-5889-4a44-aa46-7e636cf1fc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 11. Delta Tableへの保存\n",
    "\n",
    "ローカルディスク上のデータはクラスター終了時に消えてしまうため、\n",
    "Delta Tableに保存して永続化します。\n",
    "\n",
    "次回以降は、インデックス作成をスキップしてDelta Tableからデータを読み込んでクエリを実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe98a95-b4c0-469d-b734-bbd289689b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ takaakiyayoi_catalog.default.graphrag_entities\n✓ takaakiyayoi_catalog.default.graphrag_relationships\n✓ takaakiyayoi_catalog.default.graphrag_community_reports\n✓ takaakiyayoi_catalog.default.graphrag_communities\n✓ takaakiyayoi_catalog.default.graphrag_text_units\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"graphrag_entities\": \"entities.parquet\",\n",
    "    \"graphrag_relationships\": \"relationships.parquet\",\n",
    "    \"graphrag_community_reports\": \"community_reports.parquet\",\n",
    "    \"graphrag_communities\": \"communities.parquet\",\n",
    "    \"graphrag_text_units\": \"text_units.parquet\",\n",
    "}\n",
    "\n",
    "for table_name, file_name in tables.items():\n",
    "    file_path = f\"file:{OUTPUT_DIR}/{file_name}\"\n",
    "    spark.read.parquet(file_path).write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.{table_name}\")\n",
    "    print(f\"✓ {CATALOG}.{SCHEMA}.{table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65250e6f-ea8d-431b-b4a0-a754e3c21774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 12. (オプション) Delta Tableからの読み込み\n",
    "\n",
    "保存したDelta Tableからデータを読み込んでクエリを実行する例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4854c68a-1484-48e1-adbd-94af649e23d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Delta Tableからデータを読み込む場合\n",
    "# entities = spark.read.table(f\"{CATALOG}.{SCHEMA}.graphrag_entities\").toPandas()\n",
    "# communities = spark.read.table(f\"{CATALOG}.{SCHEMA}.graphrag_communities\").toPandas()\n",
    "# community_reports = spark.read.table(f\"{CATALOG}.{SCHEMA}.graphrag_community_reports\").toPandas()\n",
    "# text_units = spark.read.table(f\"{CATALOG}.{SCHEMA}.graphrag_text_units\").toPandas()\n",
    "# relationships = spark.read.table(f\"{CATALOG}.{SCHEMA}.graphrag_relationships\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72072c1a-1df7-4582-8c3e-2036db52d2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、以下を実行しました:\n",
    "\n",
    "1. **インデックス作成**: テキストからエンティティ、リレーションシップ、コミュニティを抽出\n",
    "2. **可視化**: ナレッジグラフをインタラクティブに表示\n",
    "3. **Global Search**: データセット全体に関する質問に回答\n",
    "4. **Local Search**: 特定のエンティティに関する質問に回答\n",
    "5. **永続化**: 結果をDelta Tableに保存\n",
    "\n",
    "### 制約事項\n",
    "\n",
    "- **LLM**: OpenAI APIまたはAzure OpenAIが必要(FMAPIは非対応)\n",
    "- **ストレージ**: LanceDBの制約により、クラスターのローカルディスクを使用\n",
    "- **コスト**: インデックス作成時にLLMへの多数のAPI呼び出しが発生"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "graphrag_databricks_complete",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
